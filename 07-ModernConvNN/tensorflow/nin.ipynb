{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "nin.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "dLbOqWFTQDkp"
      },
      "source": [
        "# Network in Network (NiN)\n",
        ":label:`sec_nin`\n",
        "\n",
        "LeNet, AlexNet, and VGG all share a common design pattern:\n",
        "extract features exploiting *spatial* structure\n",
        "via a sequence of convolution and pooling layers\n",
        "and then post-process the representations via fully-connected layers.\n",
        "The improvements upon LeNet by AlexNet and VGG mainly lie\n",
        "in how these later networks widen and deepen these two modules.\n",
        "Alternatively, one could imagine using fully-connected layers\n",
        "earlier in the process.\n",
        "However, a careless use of dense layers might give up the\n",
        "spatial structure of the representation entirely,\n",
        "*network in network* (*NiN*) blocks offer an alternative.\n",
        "They were proposed based on a very simple insight:\n",
        "to use an MLP on the channels for each pixel separately :cite:`Lin.Chen.Yan.2013`.\n",
        "\n",
        "\n",
        "## NiN Blocks\n",
        "\n",
        "Recall that the inputs and outputs of convolutional layers\n",
        "consist of four-dimensional tensors with axes\n",
        "corresponding to the example, channel, height, and width.\n",
        "Also recall that the inputs and outputs of fully-connected layers\n",
        "are typically two-dimensional tensors corresponding to the example and feature.\n",
        "The idea behind NiN is to apply a fully-connected layer\n",
        "at each pixel location (for each height and  width).\n",
        "If we tie the weights across each spatial location,\n",
        "we could think of this as a $1\\times 1$ convolutional layer\n",
        "(as described in :numref:`sec_channels`)\n",
        "or as a fully-connected layer acting independently on each pixel location.\n",
        "Another way to view this is to think of each element in the spatial dimension\n",
        "(height and width) as equivalent to an example\n",
        "and a channel as equivalent to a feature.\n",
        "\n",
        ":numref:`fig_nin` illustrates the main structural differences\n",
        "between VGG and NiN, and their blocks.\n",
        "The NiN block consists of one convolutional layer\n",
        "followed by two $1\\times 1$ convolutional layers that act as\n",
        "per-pixel fully-connected layers with ReLU activations.\n",
        "The convolution window shape of the first layer is typically set by the user.\n",
        "The subsequent window shapes are fixed to $1 \\times 1$.\n",
        "\n",
        "![Comparing architectures of VGG and NiN, and their blocks.](https://github.com/serivan/DeepLearning/blob/master/07-ModernConvNN/img/nin.svg?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_nin`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLZ41x9XQDkv",
        "outputId": "f04fc137-dfe9-4140-dd81-f39694b65a14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install d2l"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: d2l in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l) (2.23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l) (1.1.5)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (4.10.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.1.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (7.6.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.3.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.3.5)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.1.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.5.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l) (1.15.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (1.0.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (3.5.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l) (4.8.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l) (2.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (0.12.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->d2l) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (1.3.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (4.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l) (21.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l) (2018.9)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l) (1.11.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 3,
        "tab": [
          "tensorflow"
        ],
        "id": "IPAvHOPLQDkw",
        "outputId": "7a8d214d-d2c8-4608-86ee-a6d2308dec0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from d2l import tensorflow as d2l\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIVd4HKNUgJM",
        "outputId": "b76be1f7-c755-4110-c5fe-ac15cbb8c2d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-28CJltTW9c"
      },
      "source": [
        "def nin_block(num_channels, kernel_size, strides, padding):\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(num_channels, kernel_size, strides=strides,\n",
        "                               padding=padding, activation='relu'),\n",
        "        tf.keras.layers.Conv2D(num_channels, kernel_size=1,\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.Conv2D(num_channels, kernel_size=1,\n",
        "                               activation='relu')])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "VFU3SmTdQDkx"
      },
      "source": [
        "## NiN Model\n",
        "\n",
        "The original NiN network was proposed shortly after AlexNet\n",
        "and clearly draws some inspiration.\n",
        "NiN uses convolutional layers with window shapes\n",
        "of $11\\times 11$, $5\\times 5$, and $3\\times 3$,\n",
        "and the corresponding numbers of output channels are the same as in AlexNet. Each NiN block is followed by a maximum pooling layer\n",
        "with a stride of 2 and a window shape of $3\\times 3$.\n",
        "\n",
        "One significant difference between NiN and AlexNet\n",
        "is that NiN avoids fully-connected layers altogether.\n",
        "Instead, NiN uses an NiN block with a number of output channels equal to the number of label classes, followed by a *global* average pooling layer,\n",
        "yielding a vector of logits.\n",
        "One advantage of NiN's design is that it significantly\n",
        "reduces the number of required model parameters.\n",
        "However, in practice, this design sometimes requires\n",
        "increased model training time.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "tensorflow"
        ],
        "id": "6uipEzOSQDky"
      },
      "source": [
        "def net():\n",
        "    return tf.keras.models.Sequential([\n",
        "        nin_block(96, kernel_size=11, strides=4, padding='valid'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        nin_block(256, kernel_size=5, strides=1, padding='same'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        nin_block(384, kernel_size=3, strides=1, padding='same'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        # There are 10 label classes\n",
        "        nin_block(10, kernel_size=3, strides=1, padding='same'),\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Reshape((1, 1, 10)),\n",
        "        # Transform the four-dimensional output into two-dimensional output\n",
        "        # with a shape of (batch size, 10)\n",
        "        tf.keras.layers.Flatten(),\n",
        "        ])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 8,
        "id": "LP2wNlxxQDky"
      },
      "source": [
        "We create a data example to see the output shape of each block.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 11,
        "tab": [
          "tensorflow"
        ],
        "id": "vyABQPckQDkz",
        "outputId": "a2b2e55c-0c38-4c6b-a7a3-8659c5983045",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X = tf.random.uniform((1, 224, 224, 1))\n",
        "for layer in net().layers:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape:\t (1, 54, 54, 96)\n",
            "MaxPooling2D output shape:\t (1, 26, 26, 96)\n",
            "Sequential output shape:\t (1, 26, 26, 256)\n",
            "MaxPooling2D output shape:\t (1, 12, 12, 256)\n",
            "Sequential output shape:\t (1, 12, 12, 384)\n",
            "MaxPooling2D output shape:\t (1, 5, 5, 384)\n",
            "Dropout output shape:\t (1, 5, 5, 384)\n",
            "Sequential output shape:\t (1, 5, 5, 10)\n",
            "GlobalAveragePooling2D output shape:\t (1, 10)\n",
            "Reshape output shape:\t (1, 1, 1, 10)\n",
            "Flatten output shape:\t (1, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 12,
        "id": "vZNAANbvQDk1"
      },
      "source": [
        "## Training\n",
        "\n",
        "As before we use Fashion-MNIST to train the model.\n",
        "NiN's training is similar to that for AlexNet and VGG.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxmaEnaYTHGl",
        "outputId": "762f322b-58fc-4efc-ccce-f48cd0eea772",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 20 15:29:40 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    60W / 149W |   2629MiB / 11441MiB |      2%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 13,
        "tab": [
          "tensorflow"
        ],
        "id": "k7-gn6b7QDk2",
        "outputId": "0a92dbe1-b540-48b4-ab5f-baa0ac5bd01f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr, num_epochs, batch_size = 0.1, 10, 128\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
        "print(d2l.try_gpu())\n",
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow.python.eager.context._EagerDeviceContext object at 0x7fe485c1ddc0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 14,
        "id": "dZhEKM-XQDk2"
      },
      "source": [
        "## Summary\n",
        "\n",
        "* NiN uses blocks consisting of a convolutional layer and multiple $1\\times 1$ convolutional layers. This can be used within the convolutional stack to allow for more per-pixel nonlinearity.\n",
        "* NiN removes the fully-connected layers and replaces them with global average pooling (i.e., summing over all locations) after reducing the number of channels to the desired number of outputs (e.g., 10 for Fashion-MNIST).\n",
        "* Removing the fully-connected layers reduces overfitting. NiN has dramatically fewer parameters.\n",
        "* The NiN design influenced many subsequent CNN designs.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Tune the hyperparameters to improve the classification accuracy.\n",
        "1. Why are there two $1\\times 1$ convolutional layers in the NiN block? Remove one of them, and then observe and analyze the experimental phenomena.\n",
        "1. Calculate the resource usage for NiN.\n",
        "    1. What is the number of parameters?\n",
        "    1. What is the amount of computation?\n",
        "    1. What is the amount of memory needed during training?\n",
        "    1. What is the amount of memory needed during prediction?\n",
        "1. What are possible problems with reducing the $384 \\times 5 \\times 5$ representation to a $10 \\times 5 \\times 5$ representation in one step?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 17,
        "tab": [
          "tensorflow"
        ],
        "id": "nC97CZQ0QDk3"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/332)\n"
      ]
    }
  ]
}