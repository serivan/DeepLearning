{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Talos-01-Hyperparameter_Optimization_Keras.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7vBKtlxYSSw",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://raw.githubusercontent.com/autonomio/hyperio/master/logo.png' width=250px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a_x5TlUYSS5",
        "colab_type": "text"
      },
      "source": [
        "# Predicting Diabetes with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uYNn23rYSTB",
        "colab_type": "text"
      },
      "source": [
        "### A Very Short Introduction to Hyperparameter Optimization with Talos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCF6VI8TYSTG",
        "colab_type": "text"
      },
      "source": [
        "The goal of a Talos experiment, is to find a set of suitable hyperparameters for Keras model. In order to do this, you need to have three things: \n",
        "\n",
        "- Keras model \n",
        "- Talos hyperparameter dictionary\n",
        "- Talos experiment configuration\n",
        "\n",
        "Below we will briefly overview each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab3q9L5SYSTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e2158fa-53e3-4884-a855-cfb8ddf28295"
      },
      "source": [
        "!pip install talos"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from talos) (1.17.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from talos) (0.25.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from talos) (2.2.5)\n",
            "Collecting astetik\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/ba/f8622951da73d9b47b45bb847112c388651f9c6e413e712954f260301d9f/astetik-1.9.9.tar.gz\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from talos) (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from talos) (4.28.1)\n",
            "Collecting chances\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/d8/d61112d7476dc3074b855f1edd8556cde9b49b7106853f0b060109dd4c82/chances-0.1.9.tar.gz\n",
            "Collecting kerasplotlib\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/2e/b8628bfef6a817da9be863f650cf67187676b10d27d94b23f248da35d2b4/kerasplotlib-0.1.4.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from talos) (2.21.0)\n",
            "Collecting scipy==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/e6/6d4edaceee6a110ecf6f318482f5229792f143e468b34a631f5a0899f56d/scipy-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from wrangle->talos) (0.10.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2.6.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->talos) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->talos) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->talos) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->talos) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->talos) (2.8.0)\n",
            "Collecting geonamescache\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c1/efb823270c8526b2f4f3eb8c804c5a0a55277267ad2312f5eb47bd9cc370/geonamescache-1.1.0-py3-none-any.whl (830kB)\n",
            "\u001b[K     |████████████████████████████████| 839kB 35.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->talos) (0.21.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (1.24.3)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->wrangle->talos) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->talos) (0.14.0)\n",
            "Building wheels for collected packages: talos, wrangle, astetik, chances, kerasplotlib\n",
            "  Building wheel for talos (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for talos: filename=talos-0.6.3-cp36-none-any.whl size=49626 sha256=ac66838616140e4bef4e2fa2154c60131ed34f9c726ec14a4afb348044aa7811\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/d7/6b/86fd8b1fc7cfbd2c54796412f86efb5fb6a3a5c734014f6a66\n",
            "  Building wheel for wrangle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrangle: filename=wrangle-0.6.7-cp36-none-any.whl size=49894 sha256=48e38728d291851c5c482e5dcba0074bab903f73920fd5e9073a4a325a71621d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/1b/50/d0403ce6ef269e364894da7b50db68db14c4ac62c577561e2d\n",
            "  Building wheel for astetik (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for astetik: filename=astetik-1.9.9-cp36-none-any.whl size=56960 sha256=1d1a4388e64149904159c46437b5a3b771c76d1bd2443839e921b6f377949879\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/70/21/c475cd079ec401dd6e1b9b1d42b4c38554ce12679bfb214aad\n",
            "  Building wheel for chances (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chances: filename=chances-0.1.9-cp36-none-any.whl size=41609 sha256=f54f8e8fc02ca60b3ab1b8382a7d8765ce9bdcbf1e7d0f55305889781bd68532\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/33/46/c871b94249bd57d17797d049b3dff8e3a09c315afb67eb14c6\n",
            "  Building wheel for kerasplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kerasplotlib: filename=kerasplotlib-0.1.4-cp36-none-any.whl size=3579 sha256=cfe92af8bb14ecbe6f30973bcb2b0ffa7785a576370aa08212574e0777712196\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/6b/4c/e1fc6d7d8811940fbea1147b1519c7baa6933e4baeff904433\n",
            "Successfully built talos wrangle astetik chances kerasplotlib\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy, wrangle, geonamescache, astetik, chances, kerasplotlib, talos\n",
            "  Found existing installation: scipy 1.3.1\n",
            "    Uninstalling scipy-1.3.1:\n",
            "      Successfully uninstalled scipy-1.3.1\n",
            "Successfully installed astetik-1.9.9 chances-0.1.9 geonamescache-1.1.0 kerasplotlib-0.1.4 scipy-1.2.0 talos-0.6.3 wrangle-0.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBo6Kt6HYSTg",
        "colab_type": "text"
      },
      "source": [
        "### The Keras Model\n",
        "\n",
        "As a model, any Keras model will do. Let's consider as an example a very simple model that makes a prediction on the classic *Pima Indians Diabetes* dataset. A brief overview of the dataset can be found [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database) and the dataset we will use can be found [here](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv). The below model does not require you to separately download the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smTGA2TsYSTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import loadtxt\n",
        "\n",
        "dataset = loadtxt(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
        "x = dataset[:,0:8]\n",
        "y = dataset[:, 8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLCuqSpsYSTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "0d698e2f-10c9-4d01-fbba-cfb36dd275af"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def diabetes():\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(X, Y, epochs=100, batch_size=10, verbose=0)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ8173NsYSUG",
        "colab_type": "text"
      },
      "source": [
        "### Talos Hyperparameter Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tQSBHg7YSUK",
        "colab_type": "text"
      },
      "source": [
        "Let's prepare for an experiment where we will optimize against three common attributes:\n",
        "\n",
        "- neurons on the first layer\n",
        "- activations\n",
        "- batch_sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmmQFga2YSUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.activations import relu, elu\n",
        "\n",
        "p = {\n",
        "    'first_neuron': [12, 24, 48],\n",
        "    'activation': ['relu', 'elu'],\n",
        "    'batch_size': [10, 20, 30]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXFJm_cuYSUV",
        "colab_type": "text"
      },
      "source": [
        "### Configuring the Keras Model for Talos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo9CQoV_YSUX",
        "colab_type": "text"
      },
      "source": [
        "In order to prepare a Keras model for a Talos experiment, we need to do four things:\n",
        "\n",
        "- add input parameters to the function\n",
        "- replace the hyperparameter inputs with references to params dictionary\n",
        "- make sure model.fit() stores the history object\n",
        "- modify the output of the model\n",
        "\n",
        "These steps are always the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur8kiNlrYSUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add input parameters to the function\n",
        "def diabetes(x_train, y_train, x_val, y_val, params):\n",
        "    print(\"\\nParams:\",params)\n",
        "    # replace the hyperparameter inputs with references to params dictionary \n",
        "    model = Sequential()\n",
        "    model.add(Dense(params['first_neuron'], input_dim=8, activation=params['activation']))\n",
        "    #model.add(Dense(8, activation=params['activation']))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # make sure history object is returned by model.fit()\n",
        "    out = model.fit(x=x, \n",
        "                    y=y,\n",
        "                    validation_data=[x_val, y_val],\n",
        "                    epochs=100,\n",
        "                    batch_size=params['batch_size'],\n",
        "                    verbose=0)\n",
        "    \n",
        "    # modify the output model\n",
        "    return out, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-r5w4paYSUl",
        "colab_type": "text"
      },
      "source": [
        "That's it, there is nothing more to it. A more complicated experiment would just entail more of the same in terms of the way the params dictionary references are made. Otherwise the changes would always be exactly the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nafARgGYSUp",
        "colab_type": "text"
      },
      "source": [
        "### Talos Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RXzSl8dYpwa",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J9FCKAKYSUs",
        "colab_type": "text"
      },
      "source": [
        "The Talos experiment is performed through the Scan() command. In case you don't have Talos installed already, you can do that now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGH8kQIyYSUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import talos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQOZDrqBYSU5",
        "colab_type": "text"
      },
      "source": [
        "While many configurations are possible, the only things that you absolutely must input to a Talos experiment are: \n",
        "\n",
        "- x\n",
        "- y\n",
        "- params (the dictionary 'p' we created above)\n",
        "- model (the 'diabetes' we created above)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mJDk-u1YSU8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "outputId": "d74cef0e-10a3-45b4-fae7-6247017aebc8"
      },
      "source": [
        "t = talos.Scan(x=x, y=y, params=p, model=diabetes, experiment_name='diabetes')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'relu', 'batch_size': 10, 'first_neuron': 12}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  6%|▌         | 1/18 [00:34<09:49, 34.66s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'relu', 'batch_size': 10, 'first_neuron': 24}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 11%|█         | 2/18 [01:09<09:14, 34.67s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'relu', 'batch_size': 10, 'first_neuron': 48}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 17%|█▋        | 3/18 [01:43<08:38, 34.55s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'relu', 'batch_size': 20, 'first_neuron': 12}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 22%|██▏       | 4/18 [02:00<06:51, 29.38s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'relu', 'batch_size': 20, 'first_neuron': 24}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 28%|██▊       | 5/18 [02:18<05:36, 25.89s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'relu', 'batch_size': 20, 'first_neuron': 48}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 6/18 [02:36<04:43, 23.59s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'relu', 'batch_size': 30, 'first_neuron': 12}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 39%|███▉      | 7/18 [02:48<03:41, 20.10s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'relu', 'batch_size': 30, 'first_neuron': 24}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 44%|████▍     | 8/18 [03:01<02:57, 17.73s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'relu', 'batch_size': 30, 'first_neuron': 48}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 9/18 [03:12<02:23, 15.93s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'elu', 'batch_size': 10, 'first_neuron': 12}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 56%|█████▌    | 10/18 [03:46<02:50, 21.30s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'elu', 'batch_size': 10, 'first_neuron': 24}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 61%|██████    | 11/18 [04:20<02:56, 25.19s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'elu', 'batch_size': 10, 'first_neuron': 48}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 12/18 [04:56<02:49, 28.24s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'elu', 'batch_size': 20, 'first_neuron': 12}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 72%|███████▏  | 13/18 [05:14<02:05, 25.14s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'elu', 'batch_size': 20, 'first_neuron': 24}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 78%|███████▊  | 14/18 [05:31<01:31, 22.87s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'elu', 'batch_size': 20, 'first_neuron': 48}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 83%|████████▎ | 15/18 [05:49<01:04, 21.40s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'elu', 'batch_size': 30, 'first_neuron': 12}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 89%|████████▉ | 16/18 [06:01<00:37, 18.64s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'elu', 'batch_size': 30, 'first_neuron': 24}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 94%|█████████▍| 17/18 [06:14<00:16, 16.74s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params: {'activation': 'elu', 'batch_size': 30, 'first_neuron': 48}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 18/18 [06:26<00:00, 15.27s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}