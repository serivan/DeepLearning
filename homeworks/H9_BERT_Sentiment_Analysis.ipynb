{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 9: BERT Sentiment Analysis\n",
        "\n",
        "*Exercise*: Build your own BERT classifier network and try to achieve the highest possible accuracy on Twitter Dataset (check the TODO items). ee also the [Sentiment_Bert](https://colab.research.google.com/github/serivan/DeepLearning/blob/master/10-AttentionMechanisms/pytorch/Sentiment_Bert.ipynb) Notebook.\n",
        "\n",
        "Moreover you can consider to use Grid search or Randomized search or Optuna in order to define the hyperparameters."
      ],
      "metadata": {
        "id": "cVQEHqccegIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Twitter Sentiment Analysis**\n",
        "\n",
        "*My ridiculous dog is amazing. [sentiment: positive]*\n",
        "\n",
        "With all of the tweets circulating every second it is hard to tell whether the sentiment behind a specific tweet will impact a company, or a person's, brand for being viral (positive), or devastate profit because it strikes a negative tone. Capturing sentiment in language is important in these times where decisions and reactions are created and updated in seconds. But, which words actually lead to the sentiment description? In this competition you will need to pick out the part of the tweet (word or phrase) that reflects the sentiment.\n",
        "\n",
        "Help build your skills in this important area with this broad dataset of tweets. Work on your technique to grab a top spot in this competition. What words in tweets support a positive, negative, or neutral sentiment? How can you help make that determination using machine learning tools?\n",
        "\n",
        "\n",
        "Useful link:\n",
        "\n",
        "\n",
        "*   [Dataset](https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset)\n",
        "*   [Competition](https://www.kaggle.com/competitions/tweet-sentiment-extraction/overview)\n",
        "\n"
      ],
      "metadata": {
        "id": "2YvR2G4scELe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the dataset and install libraries"
      ],
      "metadata": {
        "id": "Y0AYIjQlcctX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# if present, use the gpu as a device\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "KtdO5sNHB67j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f413b56-e28e-471e-9fce-adc0f8b41228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQeYe6cM2ofc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install transformers\n",
        "!wget https://raw.githubusercontent.com/serivan/DeepLearning/master/Datasets/Tweets.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset preprocessing**"
      ],
      "metadata": {
        "id": "-nHENLi03EQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Tweets.csv')\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "df['labels'] = [2 if v == \"positive\" else 0 if v == \"negative\" else 1 for v in df.sentiment.tolist()]\n",
        "df.drop([\"textID\", \"selected_text\", \"sentiment\"], axis=1, inplace=True)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "14dWmndV4uf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a8e95dc3-0241-48dc-b464-809e4ca458a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  labels\n",
              "0                    I`d have responded, if I were going       1\n",
              "1          Sooo SAD I will miss you here in San Diego!!!       0\n",
              "2                              my boss is bullying me...       0\n",
              "3                         what interview! leave me alone       0\n",
              "4       Sons of ****, why couldn`t they put them on t...       0\n",
              "...                                                  ...     ...\n",
              "27476   wish we could come see u on Denver  husband l...       0\n",
              "27477   I`ve wondered about rake to.  The client has ...       0\n",
              "27478   Yay good for both of you. Enjoy the break - y...       2\n",
              "27479                         But it was worth it  ****.       2\n",
              "27480     All this flirting going on - The ATG smiles...       1\n",
              "\n",
              "[27480 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1748e4e3-e6f3-4b25-9912-15e5dc5dfc4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27476</th>\n",
              "      <td>wish we could come see u on Denver  husband l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27477</th>\n",
              "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27478</th>\n",
              "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27479</th>\n",
              "      <td>But it was worth it  ****.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27480</th>\n",
              "      <td>All this flirting going on - The ATG smiles...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27480 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1748e4e3-e6f3-4b25-9912-15e5dc5dfc4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1748e4e3-e6f3-4b25-9912-15e5dc5dfc4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1748e4e3-e6f3-4b25-9912-15e5dc5dfc4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenizer and data processing"
      ],
      "metadata": {
        "id": "-RnJzyyl3AF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_bert(data, max_len):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in data:\n",
        "        encoded_sent = tokenizer(sent,\n",
        "                                 padding='max_length',  \n",
        "                                 truncation=True,       \n",
        "                                 max_length=max_len) \n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "\n",
        "#TODO: Load the BERT tokenizer\n",
        "tokenizer ="
      ],
      "metadata": {
        "id": "yO_Iasvq6w_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.text.tolist()\n",
        "y = df.labels.tolist()\n",
        "\n",
        "# TODO: Split the data in train, validation and test set\n",
        "\n",
        "X_train, X_test, y_train, y_test = \n",
        "X_train, X_val, y_train, y_val = "
      ],
      "metadata": {
        "id": "fGWPPPlB7Zzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Compute a max_len (different strategies are possible...)\n",
        "max_len = \n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set, the validation set and the test set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train, max_len)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val,  max_len)\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test, max_len)"
      ],
      "metadata": {
        "id": "ZzKMpCik7w0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "# For fine-tuning BERT, it's recommended a batch size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=1)"
      ],
      "metadata": {
        "id": "T_TapRif77zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the model"
      ],
      "metadata": {
        "id": "mcCtvM1X28sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\#TODO Set the hyperparameters manually or using **grid search**"
      ],
      "metadata": {
        "id": "hVwvoLimhpVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        #TODO: define the model\n",
        "        pass\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "\n",
        "        # TODO: compute the forward pass\n",
        "\n",
        "        pass"
      ],
      "metadata": {
        "id": "XMUVmtafClDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "#Training procedure\n",
        "\n",
        "#TODO: Specify loss function\n",
        "loss_fn = \n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "#Used in train\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False, accumulation=16):\n",
        "    print(\"Start training...\\n\")\n",
        "\n",
        "    #list to be returned\n",
        "    train_losses=[]\n",
        "    train_accs=[]\n",
        "    val_losses=[]\n",
        "    val_accs=[]\n",
        "\n",
        "    #For the first step of evaluation\n",
        "    eval_loss=10000\n",
        "    best_model=None\n",
        "\n",
        "    for epoch_i in range(epochs):\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "        acc = 0\n",
        "        total = 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                  #Set the previous grad to 0 \n",
        "                  model.zero_grad()\n",
        "                  # Perform a forward pass. This will return logits.\n",
        "                  logits = model(b_input_ids, b_attn_mask)\n",
        "                  # Compute loss and accumulate the loss values\n",
        "                  loss = loss_fn(logits, b_labels)\n",
        "                  loss /= accumulation\n",
        "\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Accumulation step. It's fondamental when you try to train BERT on Colab GPUs, it avoids the error CUDA_OUT_OF_MEMORY \n",
        "            if (step + 1) % accumulation == 0 or step+1 == len(train_dataloader):\n",
        "              scaler.step(optimizer)\n",
        "              scaler.update()\n",
        "\n",
        "\n",
        "        # Print training results\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Reset batch tracking variables\n",
        "        batch_loss, batch_counts = 0, 0\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        \n",
        "        predictions = torch.max(logits, 1).indices.to(device)\n",
        "\n",
        "        acc += (predictions.detach().cpu().numpy() == b_labels.detach().cpu().numpy()).sum()\n",
        "        total += len(b_labels)\n",
        "\n",
        "        epoch_acc = acc*100/total\n",
        "        train_accs.append(epoch_acc)\n",
        "        print(\"-\"*70)\n",
        "\n",
        "\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "            val_losses.append(val_loss)\n",
        "            val_accs.append(val_accuracy)\n",
        "            if val_loss <= eval_loss:\n",
        "              eval_loss = val_loss\n",
        "              best_model = model\n",
        "\n",
        "            # Print performance over the entire training data            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "    return train_losses, train_accs, val_losses, val_accs, best_model\n"
      ],
      "metadata": {
        "id": "GxwSugRVCpFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def initialize_model():\n",
        "    bert_classifier = BertClassifier()\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    #TODO: Choose an optimizer\n",
        "    optimizer = \n",
        "\n",
        "    return bert_classifier, optimizer"
      ],
      "metadata": {
        "id": "OpgjTM2fCtA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "\n",
        "epochs = 4\n",
        "accumulation = 16\n",
        "evaluation = True\n",
        "\n",
        "bert_classifier, optimizer = initialize_model()\n",
        "train_losses, train_accs, val_losses, val_accs, best_model = train(bert_classifier, train_dataloader, val_dataloader, epochs, evaluation, accumulation)"
      ],
      "metadata": {
        "id": "vNGChnvZCu3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test your model"
      ],
      "metadata": {
        "id": "XLJ_7QTj24e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(range(1, epochs+1), train_losses, label=\"Training\")\n",
        "plt.plot(range(1, epochs+1), val_losses, label=\"Validation\")\n",
        "plt.xlabel(\"No. of Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.legend(loc=\"center right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gr1phV0jCz4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, epochs+1), train_accs, label=\"Training\")\n",
        "plt.plot(range(1, epochs+1), val_accs, label=\"Validation\")\n",
        "plt.xlabel(\"No. of Epoch\")\n",
        "plt.ylabel(\"Accuracy %\")\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5pUlMiK4C2fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, val_dataloader):\n",
        "    model.eval()\n",
        "    predictions=[]\n",
        "   \n",
        "    for batch in val_dataloader:\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        predictions.append(int(preds.detach().cpu().numpy()))\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "_LjASALd1ALe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predictions = predict(bert_classifier, test_dataloader)\n",
        "\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "5CGsIbp21CRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.to(device)\n",
        "predictions = predict(best_model, test_dataloader)\n",
        "\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "YGw42Xrn1D5D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}