{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZJi3FbtEoROw"
   },
   "source": [
    "# Linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/home/iserina/.local/bin/pip\", line 7, in <module>\r\n",
      "    from pip._internal import main\r\n",
      "ModuleNotFoundError: No module named 'pip._internal'\r\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet-cu100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "JaxEHafOoTYP",
    "outputId": "6fb9e843-566c-46c0-bd80-b010da04cded"
   },
   "outputs": [],
   "source": [
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.697347Z",
     "start_time": "2019-01-22T06:59:36.344203Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZG9wPL6XoRO6"
   },
   "outputs": [],
   "source": [
    "from mxnet import nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WIdaop6voRPL"
   },
   "source": [
    "In MXNet scalars are NDArrays with just one element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.723391Z",
     "start_time": "2019-01-22T06:59:37.701297Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "w_AZn-J1oRPO",
    "outputId": "95c54840-38f4-4d42-e328-38af9708dc06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x + y =  \n",
      "[5. 5.]\n",
      "<NDArray 2 @cpu(0)>\n",
      "x * y =  \n",
      "[6. 4.]\n",
      "<NDArray 2 @cpu(0)>\n",
      "x / y =  \n",
      "[1.5 4. ]\n",
      "<NDArray 2 @cpu(0)>\n",
      "x ** y =  \n",
      "[9. 4.]\n",
      "<NDArray 2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x = nd.array([3.0, 4.0])\n",
    "y = nd.array([2.0, 1.0])\n",
    "\n",
    "print('x + y = ', x + y)\n",
    "print('x * y = ', x * y)\n",
    "print('x / y = ', x / y)\n",
    "print('x ** y = ', nd.power(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pcq_5AdzoRPd"
   },
   "source": [
    "We can convert any NDArray to a Python float by calling its `asscalar` method. Note that this is typically a bad idea. **While you are doing this, NDArray has to stop doing anything else in order to hand the result and the process control back to Python.** And unfortunately isn't very good at doing things in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.743361Z",
     "start_time": "2019-01-22T06:59:37.728689Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "r3UoLQ7loRPf",
    "outputId": "5a4bafd2-ba0d-4024-aabe-e932bbbe96ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3.]\n",
      "<NDArray 1 @cpu(0)>\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "xs=nd.array([3.0])\n",
    "print(xs)\n",
    "print(xs.asscalar())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16-sLmRJoRPq"
   },
   "source": [
    "## Vectors\n",
    "\n",
    "Vectors are e.g. ``[1.0,3.0,4.0,2.0]``. We use 1D NDArrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.759425Z",
     "start_time": "2019-01-22T06:59:37.748844Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kYpxvZrFoRPt",
    "outputId": "54737e05-b87f-479f-fc40-c96397b9933a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  \n",
      "[0. 1. 2. 3. 4.]\n",
      "<NDArray 5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x = nd.arange(5)\n",
    "print('x = ', x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.790373Z",
     "start_time": "2019-01-22T06:59:37.765817Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "o14pQ1vjoRP4",
    "outputId": "063183ad-6f62-4868-ee2d-5a9befe3aaaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[3.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7B5CmQwboRQC"
   },
   "source": [
    "## Length, dimensionality and shape\n",
    "\n",
    "The length of a vector is commonly called its $dimension$. As with an ordinary Python array, we can access the length of an NDArray\n",
    "by calling Python's in-built ``len()`` function.\n",
    "\n",
    "We can also access a vector's length via its `.shape` attribute.\n",
    "The shape is a tuple that lists the dimensionality along each of its axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.799655Z",
     "start_time": "2019-01-22T06:59:37.792531Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "u8SEsrLSoRQF",
    "outputId": "0114ec41-bfdd-4a95-8f3d-e3a89e7f5617",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5,), 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJPJNIt_oRQS"
   },
   "source": [
    "The word dimension is overloaded between number of axes and number of elements. **To avoid confusion, when we say *2D* array or *3D* array, we mean an array with 2 or 3 axes respectively. But if we say *$n$-dimensional* vector, we mean a vector of length $n$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.819085Z",
     "start_time": "2019-01-22T06:59:37.806667Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "LQaJzbwToRQX",
    "outputId": "0f713a1a-0295-4345-b74e-e46796b95df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2. 4. 6.]\n",
      "<NDArray 3 @cpu(0)>\n",
      "\n",
      "[12. 24. 36.]\n",
      "<NDArray 3 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "x = nd.array([1,2,3])\n",
    "y = nd.array([10,20,30])\n",
    "print(a * x)\n",
    "print(a * x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "co72Y6K9oRQf"
   },
   "source": [
    "## Matrices\n",
    "\n",
    "Just as vectors generalize scalars from order $0$ to order $1$,\n",
    "matrices generalize vectors from $1D$ to $2D$.\n",
    "Matrices, which we'll typically denote with capital letters ($A$, $B$, $C$),\n",
    "are represented in code as arrays with 2 axes.\n",
    "Visually, we can draw a matrix as a table,\n",
    "where each entry $a_{ij}$ belongs to the $i$-th row and $j$-th column.\n",
    "\n",
    "\n",
    "$$A=\\begin{pmatrix}\n",
    " a_{11} & a_{12} & \\cdots & a_{1m} \\\\\n",
    " a_{21} & a_{22} & \\cdots & a_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " a_{n1} & a_{n2} & \\cdots & a_{nm} \\\\\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.845855Z",
     "start_time": "2019-01-22T06:59:37.832911Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "696GkXlWoRQi",
    "outputId": "c6974d67-a941-4dd7-ba21-35b3cefb9c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "<NDArray 10 @cpu(0)>\n",
      "\n",
      "[[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [10. 11. 12. 13. 14. 15. 16. 17. 18. 19.]]\n",
      "<NDArray 2x10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(nd.arange(10))\n",
    "A = nd.arange(20).reshape((2,10))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UlJpeyI9oRQq"
   },
   "source": [
    "We can access elements $a_{ij}$ by specifying row $i$ and column $j$. Leaving them blank selects via `:` takes all ements in the respective dimension. \n",
    "\n",
    "We can transpose the matrix through `T`. That is, if $B = A^T$, then $b_{ij} = a_{ji}$ for any $i$ and $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.858642Z",
     "start_time": "2019-01-22T06:59:37.849556Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Rn5nYEZVoRQv",
    "outputId": "b7d95128-fdc6-4edb-8f25-33087817c40b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0. 10.]\n",
      " [ 1. 11.]\n",
      " [ 2. 12.]\n",
      " [ 3. 13.]\n",
      " [ 4. 14.]\n",
      " [ 5. 15.]\n",
      " [ 6. 16.]\n",
      " [ 7. 17.]\n",
      " [ 8. 18.]\n",
      " [ 9. 19.]]\n",
      "<NDArray 10x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YiciKLKfoRQ3"
   },
   "source": [
    "## Tensors\n",
    "\n",
    "Just as vectors generalize scalars, and matrices generalize vectors, we can increase the number of axes. When working with images the axes correspond to the height, width, and the three (RGB) color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.880386Z",
     "start_time": "2019-01-22T06:59:37.869406Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1KEUroCPoRQ5",
    "outputId": "bcee9c64-90d7-4e47-ea39-567b000e0b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (2, 3, 4)\n",
      "X = \n",
      "[[[ 0.  1.  2.  3.]\n",
      "  [ 4.  5.  6.  7.]\n",
      "  [ 8.  9. 10. 11.]]\n",
      "\n",
      " [[12. 13. 14. 15.]\n",
      "  [16. 17. 18. 19.]\n",
      "  [20. 21. 22. 23.]]]\n",
      "<NDArray 2x3x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "X = nd.arange(24).reshape((2, 3, 4))\n",
    "print('X.shape =', X.shape)\n",
    "print('X =', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wN_kyBkBoRRA"
   },
   "source": [
    "## Basic properties of tensor arithmetic\n",
    "\n",
    "Given two tensors $X$ and $Y$ with the same shape,\n",
    "$\\alpha X + Y$ has the same shape\n",
    "(numerical mathematicians call this the AXPY operation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.896390Z",
     "start_time": "2019-01-22T06:59:37.883657Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3ii5fqAmoRRD",
    "outputId": "98bc515f-306e-4a4f-cf05-d5e75cc5e796"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3,)\n",
      "(3,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "x = nd.ones(3)\n",
    "y = nd.zeros(3)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print((a * x).shape)\n",
    "print((a * x + y).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDTh4qFFoRRM"
   },
   "source": [
    "## Sums and means\n",
    "\n",
    "In math we express sums using the $\\sum$ symbol.\n",
    "To express the sum of the elements in a vector $\\mathbf{u}$ of length $d$,\n",
    "we can write $\\sum_{i=1}^d u_i$. In code, we can just call ``nd.sum()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.911193Z",
     "start_time": "2019-01-22T06:59:37.899472Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "doPodDg9oRRP",
    "outputId": "dadaa296-fc3a-4f7d-aa09-f44c882de22f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1. 1. 1.]\n",
      "<NDArray 3 @cpu(0)>\n",
      "\n",
      "[3.]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(nd.sum(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5BQaoAtoRRY"
   },
   "source": [
    "We can similarly express sums over the elements of tensors of arbitrary shape. For example, the sum of the elements of an $m \\times n$ matrix $A$ could be written $\\sum_{i=1}^{m} \\sum_{j=1}^{n} a_{ij}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.922313Z",
     "start_time": "2019-01-22T06:59:37.914364Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "M3HULeOpoRRa",
    "outputId": "861fccfd-c8e6-49ce-9f38-8b13d3cd1bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [10. 11. 12. 13. 14. 15. 16. 17. 18. 19.]]\n",
      "<NDArray 2x10 @cpu(0)>\n",
      "\n",
      "[10. 12. 14. 16. 18. 20. 22. 24. 26. 28.]\n",
      "<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "print(nd.sum(A,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNIAWCW1oRRk"
   },
   "source": [
    "A related quantity is the *mean*. \n",
    "We calculate the mean by dividing the sum by the total number of elements. In code this is ``nd.mean()``.\n",
    "\n",
    "$$\\mathrm{mean}(\\mathbf{u}) = \\frac{1}{d} \\sum_{i=1}^{d} u_i \\text{ and }\n",
    "\\mathrm{mean}(A) = \\frac{1}{n \\cdot m} \\sum_{i=1}^{m} \\sum_{j=1}^{n} a_{ij}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.933514Z",
     "start_time": "2019-01-22T06:59:37.925021Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Cl46LWodoRRm",
    "outputId": "481ef274-d0f3-4cd1-a03e-cddbd03cee12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[9.5]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[9.5]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(nd.mean(A))\n",
    "print(nd.sum(A) / A.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dz5cV6TwoRRs"
   },
   "source": [
    "## Dot products\n",
    "\n",
    "Given two vectors $\\mathbf{u}$ and $\\mathbf{v}$, the dot product $\\mathbf{u}^T \\mathbf{v}$ is a sum over the products of the corresponding elements: $\\mathbf{u}^T \\mathbf{v} = \\sum_{i=1}^{d} u_i \\cdot v_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.947256Z",
     "start_time": "2019-01-22T06:59:37.936840Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QD9aRfV_oRRx",
    "outputId": "e84c574e-17b8-46d6-ea34-7448dd8aef2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1. 2. 3. 4.]\n",
      "<NDArray 4 @cpu(0)> \n",
      "[1. 1. 1. 1.]\n",
      "<NDArray 4 @cpu(0)> \n",
      "[10.]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x = nd.arange(4) +1.0\n",
    "y = nd.ones(4)\n",
    "print(x, y, nd.dot(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qn_KU0JYoRR4"
   },
   "source": [
    "Note that we can express the dot product of two vectors ``nd.dot(u, v)`` equivalently by performing an element-wise multiplication and then a sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.958753Z",
     "start_time": "2019-01-22T06:59:37.950028Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WMwKFhkfoRR6",
    "outputId": "2cbee7c5-56c4-48e6-daf6-86677a7bc35f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[10.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_swE7Yo2oRSC"
   },
   "source": [
    "## Matrix-vector products\n",
    "\n",
    "$$A=\\begin{pmatrix}\n",
    " a_{11} & a_{12} & \\cdots & a_{1m} \\\\\n",
    " a_{21} & a_{22} & \\cdots & a_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " a_{n1} & a_{n2} & \\cdots & a_{nm} \\\\\n",
    "\\end{pmatrix},\\quad\\mathbf{x}=\\begin{pmatrix}\n",
    " x_{1}  \\\\\n",
    " x_{2} \\\\\n",
    "\\vdots\\\\\n",
    " x_{m}\\\\\n",
    "\\end{pmatrix} $$\n",
    "\n",
    "$$A\\mathbf{x}=\n",
    "\\begin{pmatrix}\n",
    "\\cdots & \\mathbf{a}^T_{1} &...  \\\\\n",
    "\\cdots & \\mathbf{a}^T_{2} & \\cdots \\\\\n",
    " & \\vdots &  \\\\\n",
    " \\cdots &\\mathbf{a}^T_n & \\cdots \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    " x_{1}  \\\\\n",
    " x_{2} \\\\\n",
    "\\vdots\\\\\n",
    " x_{m}\\\\\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    " \\mathbf{a}^T_{1} \\mathbf{x}  \\\\\n",
    " \\mathbf{a}^T_{2} \\mathbf{x} \\\\\n",
    "\\vdots\\\\\n",
    " \\mathbf{a}^T_{n} \\mathbf{x}\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "So you can think of multiplication by a matrix $A\\in \\mathbb{R}^{m \\times n}$ as a transformation that projects vectors from $\\mathbb{R}^{m}$ to $\\mathbb{R}^{n}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zj6Wy_HAoRSF"
   },
   "source": [
    "We can also use matrix-vector products to describe the calculations of each layer in a neural network.\n",
    "Expressing matrix-vector products in code with ``ndarray``, we use the same ``nd.dot()`` function as for dot products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:37.972681Z",
     "start_time": "2019-01-22T06:59:37.961622Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gEh_BboLoRSH",
    "outputId": "baea9765-054f-46aa-bba2-ff90ba81b1c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 20.  60. 100.]\n",
      "<NDArray 3 @cpu(0)>\n",
      "\n",
      "[[ 0.  2.  6. 12.]\n",
      " [ 4. 10. 18. 28.]\n",
      " [ 8. 18. 30. 44.]]\n",
      "<NDArray 3x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "A = A.reshape((3,4))\n",
    "print(nd.dot(A, x))\n",
    "print(A * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPmYNR3WoRSN"
   },
   "source": [
    "## Matrix-matrix multiplication\n",
    "\n",
    "If you've gotten the hang of dot products and matrix-vector multiplication, then matrix-matrix multiplications should be pretty straightforward.\n",
    "\n",
    "Say we have two matrices, $A \\in \\mathbb{R}^{n \\times k}$ and $B \\in \\mathbb{R}^{k \\times m}$:\n",
    "\n",
    "$$A=\\begin{pmatrix}\n",
    " a_{11} & a_{12} & \\cdots & a_{1k} \\\\\n",
    " a_{21} & a_{22} & \\cdots & a_{2k} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " a_{n1} & a_{n2} & \\cdots & a_{nk} \\\\\n",
    "\\end{pmatrix},\\quad\n",
    "B=\\begin{pmatrix}\n",
    " b_{11} & b_{12} & \\cdots & b_{1m} \\\\\n",
    " b_{21} & b_{22} & \\cdots & b_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " b_{k1} & b_{k2} & \\cdots & b_{km} \\\\\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jU3Ck9xvoRSQ"
   },
   "source": [
    "$$AB = \\begin{pmatrix}\n",
    "\\cdots & \\mathbf{a}^T_{1} &...  \\\\\n",
    "\\cdots & \\mathbf{a}^T_{2} & \\cdots \\\\\n",
    " & \\vdots &  \\\\\n",
    " \\cdots &\\mathbf{a}^T_n & \\cdots \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "\\vdots & \\vdots &  & \\vdots \\\\\n",
    " \\mathbf{b}_{1} & \\mathbf{b}_{2} & \\cdots & \\mathbf{b}_{m} \\\\\n",
    " \\vdots & \\vdots &  &\\vdots\\\\\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "\\mathbf{a}^T_{1} \\mathbf{b}_1 & \\mathbf{a}^T_{1}\\mathbf{b}_2& \\cdots & \\mathbf{a}^T_{1} \\mathbf{b}_m \\\\\n",
    " \\mathbf{a}^T_{2}\\mathbf{b}_1 & \\mathbf{a}^T_{2} \\mathbf{b}_2 & \\cdots & \\mathbf{a}^T_{2} \\mathbf{b}_m \\\\\n",
    " \\vdots & \\vdots & \\ddots &\\vdots\\\\\n",
    "\\mathbf{a}^T_{n} \\mathbf{b}_1 & \\mathbf{a}^T_{n}\\mathbf{b}_2& \\cdots& \\mathbf{a}^T_{n} \\mathbf{b}_m\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "You can think of the matrix-matrix multiplication $AB$ as simply performing $m$ matrix-vector products and stitching the results together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:38.003462Z",
     "start_time": "2019-01-22T06:59:37.989098Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "npCyI9e6oRSR",
    "outputId": "0b9c1fc0-9943-44cb-9608-003b60cb355a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 6.  6.  6.]\n",
       " [22. 22. 22.]\n",
       " [38. 38. 38.]]\n",
       "<NDArray 3x3 @cpu(0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = nd.ones(shape=(4, 3))\n",
    "nd.dot(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fDi3eqRoRSY"
   },
   "source": [
    "## Norms\n",
    "\n",
    "All norms must satisfy a handful of properties:\n",
    "\n",
    "1. $\\|\\alpha A\\| = |\\alpha| \\|A\\|$\n",
    "1. $\\|A + B\\| \\leq \\|A\\| + \\|B\\|$\n",
    "1. $\\|A\\| \\geq 0$\n",
    "1. If $\\forall {i,j}, a_{ij} = 0$, then $\\|A\\|=0$\n",
    "\n",
    "To calculate the $\\ell_2$ norm, we can just call ``nd.norm()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:38.023692Z",
     "start_time": "2019-01-22T06:59:38.010330Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uyoH478loRSa",
    "outputId": "7a51cb9c-220c-4136-ba12-c97767a07e13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[5.477226]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VGVFioAToRSf"
   },
   "source": [
    "To calculate the $\\ell_1$-norm we can simply perform the absolute value and then sum over the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T06:59:38.037641Z",
     "start_time": "2019-01-22T06:59:38.026628Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "g7AUuUNtoRSj",
    "outputId": "a817ab39-0be7-4587-a9fa-4f57203f8f07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[10.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.sum(nd.abs(x))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "linear-algebra.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
