{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "KdAi0sGq680i"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFNvCCSd680i"
      },
      "source": [
        "This project requires Python 3.7 or above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JAmaeIFg680j"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 7)\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzJaazlL680m"
      },
      "source": [
        "And TensorFlow ≥ 2.8:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jLJZmpFf680n"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "\n",
        "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YqEDo4y680o"
      },
      "source": [
        "As we did in previous chapters, let's define the default font sizes to make the figures prettier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O8TCzYLQ680o"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MArCeZd680p"
      },
      "source": [
        "And let's create the `images/deep` folder (if it doesn't already exist), and define the `save_fig()` function which is used through this notebook to save the figures in high-res for the book:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GxyA8qMJ680p"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"deep\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "3Lgo_VNGaTDT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FW4ATSKY680z"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
        "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
        "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
        "X_train, X_valid, X_test = X_train / 255, X_valid / 255, X_test / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FlLMC3rmYwTW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PJ6XCcs681F"
      },
      "source": [
        "# Reusing Pretrained Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjTdvvhY681F"
      },
      "source": [
        "### Reusing a Keras model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AynifTS681F"
      },
      "source": [
        "Let's split the fashion MNIST training set in two:\n",
        "* `X_train_A`: all images of all items except for T-shirts/tops and pullovers (classes 0 and 2).\n",
        "* `X_train_B`: a much smaller training set of just the first 200 images of T-shirts/tops and pullovers.\n",
        "\n",
        "The validation set and the test set are also split this way, but without restricting the number of images.\n",
        "\n",
        "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (trousers, dresses, coats, sandals, shirts, sneakers, bags, and ankle boots) are somewhat similar to classes in set B (T-shirts/tops and pullovers). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the chapter 14)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model A"
      ],
      "metadata": {
        "id": "kxw4oRsXZCp6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v3oBTAUK681F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c160fecc-3e08-45e3-a7a4-06e15d925520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4447 - loss: 1.5738 - val_accuracy: 0.7541 - val_loss: 0.7733\n",
            "Epoch 2/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7695 - loss: 0.7115 - val_accuracy: 0.8183 - val_loss: 0.5490\n",
            "Epoch 3/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8192 - loss: 0.5363 - val_accuracy: 0.8388 - val_loss: 0.4593\n",
            "Epoch 4/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8455 - loss: 0.4558 - val_accuracy: 0.8569 - val_loss: 0.4081\n",
            "Epoch 5/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8616 - loss: 0.4075 - val_accuracy: 0.8684 - val_loss: 0.3755\n",
            "Epoch 6/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.3758 - val_accuracy: 0.8744 - val_loss: 0.3538\n",
            "Epoch 7/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.3539 - val_accuracy: 0.8782 - val_loss: 0.3385\n",
            "Epoch 8/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8816 - loss: 0.3379 - val_accuracy: 0.8832 - val_loss: 0.3271\n",
            "Epoch 9/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8851 - loss: 0.3253 - val_accuracy: 0.8854 - val_loss: 0.3182\n",
            "Epoch 10/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8884 - loss: 0.3152 - val_accuracy: 0.8879 - val_loss: 0.3109\n",
            "Epoch 11/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.3068 - val_accuracy: 0.8889 - val_loss: 0.3048\n",
            "Epoch 12/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2995 - val_accuracy: 0.8907 - val_loss: 0.2996\n",
            "Epoch 13/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8970 - loss: 0.2932 - val_accuracy: 0.8935 - val_loss: 0.2950\n",
            "Epoch 14/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8985 - loss: 0.2875 - val_accuracy: 0.8957 - val_loss: 0.2908\n",
            "Epoch 15/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.2824 - val_accuracy: 0.8965 - val_loss: 0.2872\n",
            "Epoch 16/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9019 - loss: 0.2778 - val_accuracy: 0.8980 - val_loss: 0.2839\n",
            "Epoch 17/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.2735 - val_accuracy: 0.8987 - val_loss: 0.2809\n",
            "Epoch 18/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.2695 - val_accuracy: 0.9000 - val_loss: 0.2781\n",
            "Epoch 19/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.2658 - val_accuracy: 0.9015 - val_loss: 0.2754\n",
            "Epoch 20/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.2623 - val_accuracy: 0.9035 - val_loss: 0.2729\n"
          ]
        }
      ],
      "source": [
        "# extra code – split Fashion MNIST into tasks A and B, then train and save\n",
        "#              model A to \"my_model_A\".\n",
        "\n",
        "pos_class_id = class_names.index(\"Pullover\")\n",
        "neg_class_id = class_names.index(\"T-shirt/top\")\n",
        "\n",
        "def split_dataset(X, y):\n",
        "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
        "    y_A = y[~y_for_B]\n",
        "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
        "    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
        "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
        "        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A\n",
        "    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))\n",
        "\n",
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "X_train_B = X_train_B[:200]\n",
        "y_train_B = y_train_B[:200]\n",
        "\n",
        "tf.random.set_seed(43)\n",
        "\n",
        "model_A = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(8, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
        "                      validation_data=(X_valid_A, y_valid_A))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.evaluate(X_test_A, y_test_A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9B9hcUnbQgc",
        "outputId": "51d1b202-3688-4be3-92ff-2057add0b4a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.2921\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28984713554382324, 0.8981249928474426]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model B reaches 89.8% accuracy on its test set."
      ],
      "metadata": {
        "id": "nqK8Ks3kglg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.save(\"my_model_A.keras\")"
      ],
      "metadata": {
        "id": "6gyNZyEIbtpU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model B"
      ],
      "metadata": {
        "id": "hiDMv8DvZI_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_mqjP0Xl681G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2817c6bb-560a-411c-9f0e-57f1ed24e91b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.3924 - loss: 0.7726 - val_accuracy: 0.4599 - val_loss: 0.7258\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3885 - loss: 0.7375 - val_accuracy: 0.4560 - val_loss: 0.7038\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3992 - loss: 0.7108 - val_accuracy: 0.4629 - val_loss: 0.6855\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4320 - loss: 0.6883 - val_accuracy: 0.4896 - val_loss: 0.6691\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4761 - loss: 0.6686 - val_accuracy: 0.5341 - val_loss: 0.6540\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5253 - loss: 0.6506 - val_accuracy: 0.6004 - val_loss: 0.6398\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5855 - loss: 0.6340 - val_accuracy: 0.6686 - val_loss: 0.6263\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6671 - loss: 0.6185 - val_accuracy: 0.7260 - val_loss: 0.6133\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7262 - loss: 0.6036 - val_accuracy: 0.7606 - val_loss: 0.6007\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7825 - loss: 0.5893 - val_accuracy: 0.7893 - val_loss: 0.5882\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8148 - loss: 0.5752 - val_accuracy: 0.8210 - val_loss: 0.5760\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8202 - loss: 0.5615 - val_accuracy: 0.8417 - val_loss: 0.5641\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8522 - loss: 0.5482 - val_accuracy: 0.8556 - val_loss: 0.5524\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8625 - loss: 0.5353 - val_accuracy: 0.8675 - val_loss: 0.5409\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9029 - loss: 0.5227 - val_accuracy: 0.8734 - val_loss: 0.5295\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9273 - loss: 0.5102 - val_accuracy: 0.8793 - val_loss: 0.5182\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9359 - loss: 0.4979 - val_accuracy: 0.8863 - val_loss: 0.5073\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9386 - loss: 0.4860 - val_accuracy: 0.8912 - val_loss: 0.4966\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9386 - loss: 0.4743 - val_accuracy: 0.9011 - val_loss: 0.4862\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9412 - loss: 0.4629 - val_accuracy: 0.9060 - val_loss: 0.4760\n"
          ]
        }
      ],
      "source": [
        "# extra code – train and evaluate model B, without reusing model A\n",
        "\n",
        "tf.random.set_seed(43)\n",
        "model_B = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_B.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
        "                      validation_data=(X_valid_B, y_valid_B))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_B.evaluate(X_test_B, y_test_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq1eTyDxb21E",
        "outputId": "b242e17b-0f53-46de-d5c3-bd507a75cf27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8942 - loss: 0.4790\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4802497625350952, 0.8970000147819519]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdg4deaF681G"
      },
      "source": [
        "Model B reaches 89.7% accuracy on the test set. Now let's try reusing the pretrained model A."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reuse Model A"
      ],
      "metadata": {
        "id": "oG7XlOSjZNDS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_HsIAVmw681H"
      },
      "outputs": [],
      "source": [
        "model_A = tf.keras.models.load_model(\"my_model_A.keras\")\n",
        "model_B_on_A = tf.keras.Sequential(model_A.layers[:-1])\n",
        "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSdisWQM681H"
      },
      "source": [
        "Note that `model_B_on_A` and `model_A` actually share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build `model_B_on_A` on top of a *clone* of `model_A`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ou8b6G2P681H"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(43)  # extra code – ensure reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aLxJszNa681H"
      },
      "outputs": [],
      "source": [
        "model_A_clone = tf.keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9QJG1c3i681I"
      },
      "outputs": [],
      "source": [
        "# extra code – creating model_B_on_A just like in the previous cell\n",
        "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])\n",
        "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Fpy8IseK681I"
      },
      "outputs": [],
      "source": [
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
        "                     metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WxFsfvE9681I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11390afd-5876-4d60-9bd2-f32cbcc07749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.4408 - loss: 1.0321 - val_accuracy: 0.4797 - val_loss: 0.7935\n",
            "Epoch 2/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4396 - loss: 0.8059 - val_accuracy: 0.4718 - val_loss: 0.7363\n",
            "Epoch 3/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4453 - loss: 0.7485 - val_accuracy: 0.4768 - val_loss: 0.7185\n",
            "Epoch 4/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4581 - loss: 0.7271 - val_accuracy: 0.4916 - val_loss: 0.7069\n",
            "Epoch 1/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.5342 - loss: 0.6995 - val_accuracy: 0.5816 - val_loss: 0.6552\n",
            "Epoch 2/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6946 - loss: 0.6402 - val_accuracy: 0.6963 - val_loss: 0.6121\n",
            "Epoch 3/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7880 - loss: 0.5916 - val_accuracy: 0.7814 - val_loss: 0.5781\n",
            "Epoch 4/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8505 - loss: 0.5536 - val_accuracy: 0.8318 - val_loss: 0.5494\n",
            "Epoch 5/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8860 - loss: 0.5214 - val_accuracy: 0.8655 - val_loss: 0.5244\n",
            "Epoch 6/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9242 - loss: 0.4935 - val_accuracy: 0.8813 - val_loss: 0.5019\n",
            "Epoch 7/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9215 - loss: 0.4685 - val_accuracy: 0.8961 - val_loss: 0.4818\n",
            "Epoch 8/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9455 - loss: 0.4462 - val_accuracy: 0.9070 - val_loss: 0.4635\n",
            "Epoch 9/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9633 - loss: 0.4261 - val_accuracy: 0.9139 - val_loss: 0.4469\n",
            "Epoch 10/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9633 - loss: 0.4080 - val_accuracy: 0.9219 - val_loss: 0.4318\n",
            "Epoch 11/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9633 - loss: 0.3915 - val_accuracy: 0.9278 - val_loss: 0.4180\n",
            "Epoch 12/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9633 - loss: 0.3764 - val_accuracy: 0.9327 - val_loss: 0.4052\n",
            "Epoch 13/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9633 - loss: 0.3624 - val_accuracy: 0.9357 - val_loss: 0.3934\n",
            "Epoch 14/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9754 - loss: 0.3494 - val_accuracy: 0.9367 - val_loss: 0.3824\n",
            "Epoch 15/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9754 - loss: 0.3375 - val_accuracy: 0.9377 - val_loss: 0.3722\n",
            "Epoch 16/16\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9754 - loss: 0.3263 - val_accuracy: 0.9377 - val_loss: 0.3628\n"
          ]
        }
      ],
      "source": [
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
        "                           validation_data=(X_valid_B, y_valid_B))\n",
        "\n",
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = True\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
        "                     metrics=[\"accuracy\"])\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
        "                           validation_data=(X_valid_B, y_valid_B))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZqYFhEt681J"
      },
      "source": [
        "So, what's the final verdict?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Ji5bmhSX681J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826d85b4-697b-4a72-a275-e4ee81defb8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.3638\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3694985508918762, 0.9225000143051147]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model_B_on_A.evaluate(X_test_B, y_test_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEngbali681J"
      },
      "source": [
        "Great! We got a bit of transfer: the model's accuracy went up 2 percentage points, from 89.7% to 92.25%. This means the error rate dropped by almost 25%:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "F-2yhuXj681J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37ae3611-302d-4a50-ab72-cc973ea69bca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24757281553398036"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "1 - (100 - 92.25) / (100 -89.7)"
      ]
    }
  ]
}