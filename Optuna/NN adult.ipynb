{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T15:18:09.502978Z",
     "iopub.status.busy": "2023-07-31T15:18:09.502785Z",
     "iopub.status.idle": "2023-07-31T15:18:40.605107Z",
     "shell.execute_reply": "2023-07-31T15:18:40.601282Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 11:18:07.956951: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/nicholas/.conda/envs/optunaEnv2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-27 11:18:11.572707: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage, JournalFileStorage\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.metrics import (\n",
    "    fbeta_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.utils.validation import check_is_fitted, check_X_y\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "RANDOM_STATE = 3993\n",
    "TEST_SIZE = 0.3\n",
    "INTER_OPS = 0  # Independent non-blocking operations.\n",
    "INTRA_OPS = 0  # Internal Matrix multiplication and reductions.\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(INTER_OPS)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(INTRA_OPS)\n",
    "tf.device('/cpu:0')\n",
    "\n",
    "np.random.seed(seed=RANDOM_STATE)\n",
    "tf.random.set_seed(seed=RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T15:18:40.618954Z",
     "iopub.status.busy": "2023-07-31T15:18:40.611040Z",
     "iopub.status.idle": "2023-07-31T15:18:41.526510Z",
     "shell.execute_reply": "2023-07-31T15:18:41.523649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48842, 13)\n",
      "(34189, 13)\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"adult\"\n",
    "DROP_DATA_PERC = 0.0\n",
    "\n",
    "path = \"./dataset/\" + DATASET + \".csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "NUM_CLASSES = np.unique(df['class']).size\n",
    "scale = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "X, y = df.drop(columns='class').values, df['class'].values\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "if DROP_DATA_PERC > 0.0:\n",
    "    print(X_train.shape)\n",
    "\n",
    "    X_train, _, y_train, _ = train_test_split(\n",
    "        X_train, y_train, test_size=DROP_DATA_PERC, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T15:18:41.537363Z",
     "iopub.status.busy": "2023-07-31T15:18:41.533567Z",
     "iopub.status.idle": "2023-07-31T15:18:41.572987Z",
     "shell.execute_reply": "2023-07-31T15:18:41.571406Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    n_hidden = best_params[\"n_hidden\"]\n",
    "    hidden_units = best_params[\"hidden_units\"]\n",
    "    learning_rate = best_params[\"learning_rate\"]\n",
    "    dropout = best_params[\"dropout\"]\n",
    "    hidden_activation = best_params[\"hidden_activation\"]\n",
    "    batch_norm = best_params[\"batch_norm\"]\n",
    "    activity_regularizer = best_params[\"activity_regularizer\"]\n",
    "\n",
    "    kernel_initializer = {\n",
    "        \"relu\": \"he_uniform\",\n",
    "        \"selu\": \"lecun_normal\",\n",
    "        \"elu\": \"he_uniform\",\n",
    "        \"swish\": \"he_uniform\",\n",
    "    }.get(hidden_activation, \"glorot_uniform\")\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(\n",
    "        Input(\n",
    "            shape=X_train.shape[1:],\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    for i in range(n_hidden):\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hidden_units,\n",
    "                activation=hidden_activation,\n",
    "                activity_regularizer=tf.keras.regularizers.L2(1e-5) if activity_regularizer else None,\n",
    "                kernel_initializer=kernel_initializer,\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        if batch_norm:\n",
    "            model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        hidden_units = int(hidden_units / 2)\n",
    "\n",
    "        \n",
    "    if NUM_CLASSES > 2:\n",
    "        model.add(\n",
    "            Dense(\n",
    "                NUM_CLASSES,\n",
    "                activation=\"softmax\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            metrics='accuracy',\n",
    "        )\n",
    "    else:\n",
    "        model.add(\n",
    "            Dense(\n",
    "                1,\n",
    "                activation=\"sigmoid\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            metrics='accuracy',\n",
    "        )\n",
    "\n",
    "    model.load_weights(init_weights_pathname)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T15:18:41.582190Z",
     "iopub.status.busy": "2023-07-31T15:18:41.578499Z",
     "iopub.status.idle": "2023-07-31T15:18:41.597073Z",
     "shell.execute_reply": "2023-07-31T15:18:41.595628Z"
    }
   },
   "outputs": [],
   "source": [
    "def multi_stratified_kfold(X_train, y_train):\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    folds = list()\n",
    "    for train_index, val_index in skf.split(X_train, y_train):\n",
    "        # Get labels\n",
    "        y_train_fold = y_train[train_index]\n",
    "        y_val_fold = y_train[val_index]\n",
    "        \n",
    "        # Append folds\n",
    "        folds.append(\n",
    "            (\n",
    "                X_train[train_index],\n",
    "                X_train[val_index],\n",
    "                y_train_fold,\n",
    "                y_val_fold,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T15:18:41.605057Z",
     "iopub.status.busy": "2023-07-31T15:18:41.602042Z",
     "iopub.status.idle": "2023-07-31T15:18:46.461379Z",
     "shell.execute_reply": "2023-07-31T15:18:46.450820Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_216427/2327146705.py:1: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n",
      "  storage_name = JournalStorage(JournalFileStorage(\"./optuna.log\"))\n"
     ]
    }
   ],
   "source": [
    "storage_name = JournalStorage(JournalFileStorage(\"./optuna.log\"))\n",
    "\n",
    "study_name = DATASET + \"-study\"\n",
    "\n",
    "study = optuna.load_study(storage=storage_name, study_name=study_name)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "batch_size = best_params.pop(\"batch_size\")\n",
    "\n",
    "init_weights_pathname = \"./weights/\" + DATASET + \"/init_weights_\" + str(study.best_trial.number)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode=\"min\", restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T15:18:46.614968Z",
     "iopub.status.busy": "2023-07-31T15:18:46.613318Z",
     "iopub.status.idle": "2023-07-31T15:33:40.712258Z",
     "shell.execute_reply": "2023-07-31T15:33:40.710294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 211)               2954      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 211)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 211)              844       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 105)               22260     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 105)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 105)              420       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 106       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,584\n",
      "Trainable params: 25,952\n",
      "Non-trainable params: 632\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "570/570 [==============================] - 5s 5ms/step - loss: 0.4318 - accuracy: 0.7977 - val_loss: 0.3565 - val_accuracy: 0.8364\n",
      "Epoch 2/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3573 - accuracy: 0.8333 - val_loss: 0.3360 - val_accuracy: 0.8399\n",
      "Epoch 3/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3450 - accuracy: 0.8387 - val_loss: 0.3367 - val_accuracy: 0.8425\n",
      "Epoch 4/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3389 - accuracy: 0.8399 - val_loss: 0.3325 - val_accuracy: 0.8422\n",
      "Epoch 5/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3367 - accuracy: 0.8401 - val_loss: 0.3387 - val_accuracy: 0.8456\n",
      "Epoch 6/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3338 - accuracy: 0.8436 - val_loss: 0.3269 - val_accuracy: 0.8444\n",
      "Epoch 7/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3326 - accuracy: 0.8424 - val_loss: 0.3272 - val_accuracy: 0.8437\n",
      "Epoch 8/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3318 - accuracy: 0.8441 - val_loss: 0.3297 - val_accuracy: 0.8454\n",
      "Epoch 9/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3289 - accuracy: 0.8449 - val_loss: 0.3280 - val_accuracy: 0.8416\n",
      "Epoch 10/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3267 - accuracy: 0.8480 - val_loss: 0.3256 - val_accuracy: 0.8431\n",
      "Epoch 11/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3276 - accuracy: 0.8472 - val_loss: 0.3229 - val_accuracy: 0.8494\n",
      "Epoch 12/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3245 - accuracy: 0.8482 - val_loss: 0.3264 - val_accuracy: 0.8444\n",
      "Epoch 13/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3253 - accuracy: 0.8451 - val_loss: 0.3250 - val_accuracy: 0.8470\n",
      "Epoch 14/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3232 - accuracy: 0.8472 - val_loss: 0.3241 - val_accuracy: 0.8466\n",
      "Epoch 15/100\n",
      "570/570 [==============================] - 4s 6ms/step - loss: 0.3225 - accuracy: 0.8489 - val_loss: 0.3227 - val_accuracy: 0.8464\n",
      "Epoch 16/100\n",
      "570/570 [==============================] - 3s 4ms/step - loss: 0.3245 - accuracy: 0.8464 - val_loss: 0.3219 - val_accuracy: 0.8460\n",
      "Epoch 17/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3235 - accuracy: 0.8474 - val_loss: 0.3223 - val_accuracy: 0.8467\n",
      "Epoch 18/100\n",
      "570/570 [==============================] - 3s 4ms/step - loss: 0.3217 - accuracy: 0.8494 - val_loss: 0.3255 - val_accuracy: 0.8459\n",
      "Epoch 19/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3204 - accuracy: 0.8487 - val_loss: 0.3228 - val_accuracy: 0.8462\n",
      "Epoch 20/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3201 - accuracy: 0.8493 - val_loss: 0.3221 - val_accuracy: 0.8469\n",
      "Epoch 21/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3189 - accuracy: 0.8495 - val_loss: 0.3247 - val_accuracy: 0.8459\n",
      "Epoch 22/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3198 - accuracy: 0.8502 - val_loss: 0.3222 - val_accuracy: 0.8473\n",
      "Epoch 23/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3181 - accuracy: 0.8523 - val_loss: 0.3222 - val_accuracy: 0.8451\n",
      "Epoch 24/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3181 - accuracy: 0.8487 - val_loss: 0.3205 - val_accuracy: 0.8489\n",
      "Epoch 25/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3169 - accuracy: 0.8490 - val_loss: 0.3197 - val_accuracy: 0.8481\n",
      "Epoch 26/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3164 - accuracy: 0.8504 - val_loss: 0.3217 - val_accuracy: 0.8479\n",
      "Epoch 27/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3169 - accuracy: 0.8501 - val_loss: 0.3205 - val_accuracy: 0.8469\n",
      "Epoch 28/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3148 - accuracy: 0.8526 - val_loss: 0.3215 - val_accuracy: 0.8457\n",
      "Epoch 29/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3147 - accuracy: 0.8519 - val_loss: 0.3242 - val_accuracy: 0.8444\n",
      "Epoch 30/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3138 - accuracy: 0.8519 - val_loss: 0.3202 - val_accuracy: 0.8462\n",
      "Epoch 31/100\n",
      "570/570 [==============================] - 4s 6ms/step - loss: 0.3146 - accuracy: 0.8507 - val_loss: 0.3195 - val_accuracy: 0.8473\n",
      "Epoch 32/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3157 - accuracy: 0.8504 - val_loss: 0.3207 - val_accuracy: 0.8486\n",
      "Epoch 33/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3114 - accuracy: 0.8523 - val_loss: 0.3206 - val_accuracy: 0.8464\n",
      "Epoch 34/100\n",
      "570/570 [==============================] - 4s 6ms/step - loss: 0.3120 - accuracy: 0.8530 - val_loss: 0.3212 - val_accuracy: 0.8488\n",
      "Epoch 35/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3125 - accuracy: 0.8527 - val_loss: 0.3203 - val_accuracy: 0.8462\n",
      "Epoch 36/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3116 - accuracy: 0.8527 - val_loss: 0.3191 - val_accuracy: 0.8481\n",
      "Epoch 37/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3105 - accuracy: 0.8523 - val_loss: 0.3202 - val_accuracy: 0.8469\n",
      "Epoch 38/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3123 - accuracy: 0.8512 - val_loss: 0.3196 - val_accuracy: 0.8481\n",
      "Epoch 39/100\n",
      "570/570 [==============================] - 3s 4ms/step - loss: 0.3095 - accuracy: 0.8542 - val_loss: 0.3195 - val_accuracy: 0.8483\n",
      "Epoch 40/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3098 - accuracy: 0.8550 - val_loss: 0.3194 - val_accuracy: 0.8466\n",
      "Epoch 41/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3099 - accuracy: 0.8538 - val_loss: 0.3190 - val_accuracy: 0.8476\n",
      "Epoch 42/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3086 - accuracy: 0.8548 - val_loss: 0.3206 - val_accuracy: 0.8475\n",
      "Epoch 43/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3093 - accuracy: 0.8546 - val_loss: 0.3212 - val_accuracy: 0.8466\n",
      "Epoch 44/100\n",
      "570/570 [==============================] - 3s 4ms/step - loss: 0.3082 - accuracy: 0.8535 - val_loss: 0.3193 - val_accuracy: 0.8438\n",
      "Epoch 45/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3065 - accuracy: 0.8556 - val_loss: 0.3190 - val_accuracy: 0.8451\n",
      "Epoch 46/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3072 - accuracy: 0.8548 - val_loss: 0.3206 - val_accuracy: 0.8445\n",
      "Epoch 47/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3068 - accuracy: 0.8546 - val_loss: 0.3207 - val_accuracy: 0.8475\n",
      "Epoch 48/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3063 - accuracy: 0.8553 - val_loss: 0.3216 - val_accuracy: 0.8463\n",
      "Epoch 49/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3065 - accuracy: 0.8540 - val_loss: 0.3240 - val_accuracy: 0.8489\n",
      "Epoch 50/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3069 - accuracy: 0.8561 - val_loss: 0.3222 - val_accuracy: 0.8456\n",
      "Epoch 51/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3058 - accuracy: 0.8565 - val_loss: 0.3229 - val_accuracy: 0.8454\n",
      "Epoch 52/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3069 - accuracy: 0.8540 - val_loss: 0.3257 - val_accuracy: 0.8456\n",
      "Epoch 53/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3049 - accuracy: 0.8572 - val_loss: 0.3209 - val_accuracy: 0.8460\n",
      "Epoch 54/100\n",
      "570/570 [==============================] - 3s 4ms/step - loss: 0.3067 - accuracy: 0.8566 - val_loss: 0.3196 - val_accuracy: 0.8459\n",
      "Epoch 55/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3034 - accuracy: 0.8565 - val_loss: 0.3217 - val_accuracy: 0.8479\n",
      "Epoch 56/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3058 - accuracy: 0.8568 - val_loss: 0.3237 - val_accuracy: 0.8425\n",
      "Epoch 57/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.3032 - accuracy: 0.8564 - val_loss: 0.3215 - val_accuracy: 0.8479\n",
      "Epoch 58/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3051 - accuracy: 0.8566 - val_loss: 0.3224 - val_accuracy: 0.8462\n",
      "Epoch 59/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3041 - accuracy: 0.8567 - val_loss: 0.3229 - val_accuracy: 0.8454\n",
      "Epoch 60/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3048 - accuracy: 0.8570 - val_loss: 0.3196 - val_accuracy: 0.8462\n",
      "Epoch 61/100\n",
      "570/570 [==============================] - 4s 7ms/step - loss: 0.3045 - accuracy: 0.8569 - val_loss: 0.3232 - val_accuracy: 0.8479\n",
      "Epoch 62/100\n",
      "570/570 [==============================] - 4s 7ms/step - loss: 0.3032 - accuracy: 0.8582 - val_loss: 0.3222 - val_accuracy: 0.8424\n",
      "Epoch 63/100\n",
      "570/570 [==============================] - 4s 6ms/step - loss: 0.3039 - accuracy: 0.8568 - val_loss: 0.3209 - val_accuracy: 0.8460\n",
      "Epoch 64/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3014 - accuracy: 0.8571 - val_loss: 0.3205 - val_accuracy: 0.8450\n",
      "Epoch 65/100\n",
      "570/570 [==============================] - 4s 6ms/step - loss: 0.3019 - accuracy: 0.8582 - val_loss: 0.3210 - val_accuracy: 0.8456\n",
      "Epoch 66/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3015 - accuracy: 0.8578 - val_loss: 0.3226 - val_accuracy: 0.8437\n",
      "Epoch 67/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3017 - accuracy: 0.8581 - val_loss: 0.3210 - val_accuracy: 0.8482\n",
      "Epoch 68/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3009 - accuracy: 0.8576 - val_loss: 0.3210 - val_accuracy: 0.8460\n",
      "Epoch 69/100\n",
      "570/570 [==============================] - 4s 7ms/step - loss: 0.3007 - accuracy: 0.8587 - val_loss: 0.3226 - val_accuracy: 0.8456\n",
      "Epoch 70/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3004 - accuracy: 0.8584 - val_loss: 0.3202 - val_accuracy: 0.8479\n",
      "Epoch 71/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2987 - accuracy: 0.8599 - val_loss: 0.3199 - val_accuracy: 0.8438\n",
      "Epoch 72/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.3012 - accuracy: 0.8564 - val_loss: 0.3207 - val_accuracy: 0.8475\n",
      "Epoch 73/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.3022 - accuracy: 0.8574 - val_loss: 0.3219 - val_accuracy: 0.8476\n",
      "Epoch 74/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.2988 - accuracy: 0.8593 - val_loss: 0.3253 - val_accuracy: 0.8467\n",
      "Epoch 75/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2998 - accuracy: 0.8596 - val_loss: 0.3208 - val_accuracy: 0.8470\n",
      "Epoch 76/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.2980 - accuracy: 0.8600 - val_loss: 0.3222 - val_accuracy: 0.8450\n",
      "Epoch 77/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2993 - accuracy: 0.8580 - val_loss: 0.3236 - val_accuracy: 0.8453\n",
      "Epoch 78/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2995 - accuracy: 0.8591 - val_loss: 0.3219 - val_accuracy: 0.8462\n",
      "Epoch 79/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.2972 - accuracy: 0.8597 - val_loss: 0.3217 - val_accuracy: 0.8424\n",
      "Epoch 80/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.2979 - accuracy: 0.8595 - val_loss: 0.3229 - val_accuracy: 0.8460\n",
      "Epoch 81/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.2958 - accuracy: 0.8619 - val_loss: 0.3223 - val_accuracy: 0.8457\n",
      "Epoch 82/100\n",
      "570/570 [==============================] - 3s 4ms/step - loss: 0.2963 - accuracy: 0.8615 - val_loss: 0.3223 - val_accuracy: 0.8469\n",
      "Epoch 83/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2966 - accuracy: 0.8587 - val_loss: 0.3223 - val_accuracy: 0.8457\n",
      "Epoch 84/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2966 - accuracy: 0.8597 - val_loss: 0.3219 - val_accuracy: 0.8470\n",
      "Epoch 85/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2957 - accuracy: 0.8609 - val_loss: 0.3232 - val_accuracy: 0.8462\n",
      "Epoch 86/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.2958 - accuracy: 0.8607 - val_loss: 0.3236 - val_accuracy: 0.8457\n",
      "Epoch 87/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2958 - accuracy: 0.8606 - val_loss: 0.3228 - val_accuracy: 0.8448\n",
      "Epoch 88/100\n",
      "570/570 [==============================] - 3s 6ms/step - loss: 0.2986 - accuracy: 0.8590 - val_loss: 0.3229 - val_accuracy: 0.8440\n",
      "Epoch 89/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2955 - accuracy: 0.8615 - val_loss: 0.3247 - val_accuracy: 0.8453\n",
      "Epoch 90/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.2953 - accuracy: 0.8604 - val_loss: 0.3223 - val_accuracy: 0.8448\n",
      "Epoch 91/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2957 - accuracy: 0.8604 - val_loss: 0.3218 - val_accuracy: 0.8467\n",
      "Epoch 92/100\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2946 - accuracy: 0.8603 - val_loss: 0.3261 - val_accuracy: 0.8429\n",
      "Epoch 93/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.2936 - accuracy: 0.8627 - val_loss: 0.3258 - val_accuracy: 0.8437\n",
      "Epoch 94/100\n",
      "570/570 [==============================] - 2s 4ms/step - loss: 0.2936 - accuracy: 0.8626 - val_loss: 0.3245 - val_accuracy: 0.8426\n",
      "Epoch 95/100\n",
      "567/570 [============================>.] - ETA: 0s - loss: 0.2927 - accuracy: 0.8629Restoring model weights from the end of the best epoch: 45.\n",
      "570/570 [==============================] - 3s 5ms/step - loss: 0.2927 - accuracy: 0.8629 - val_loss: 0.3245 - val_accuracy: 0.8429\n",
      "Epoch 95: early stopping\n"
     ]
    }
   ],
   "source": [
    "base_estimator = KerasClassifier(model=create_model, epochs=100, batch_size=batch_size, validation_split=0.2, callbacks=[callback], verbose=1)\n",
    "\n",
    "\n",
    "print(base_estimator.model().summary())\n",
    "\n",
    "base_estimator.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "prediction_base = base_estimator.predict(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713/713 [==============================] - 3s 4ms/step\n",
      "Score Train: 0.859633215361666\n",
      "306/306 [==============================] - 1s 3ms/step\n",
      "Score Test: 0.8547055210537091\n"
     ]
    }
   ],
   "source": [
    "print(\"Score Train: \" + str(base_estimator.score(X_train, y_train)))\n",
    "print(\"Score Test: \" + str(base_estimator.score(X_test, y_test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glisenti-IncertezzaML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
