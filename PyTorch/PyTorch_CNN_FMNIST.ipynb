{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j1tdlYcDIFU"
      },
      "source": [
        "# Dataset Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T02:23:03.661948Z",
          "iopub.status.busy": "2022-02-05T02:23:03.661380Z",
          "iopub.status.idle": "2022-02-05T02:23:06.352001Z",
          "shell.execute_reply": "2022-02-05T02:23:06.352451Z"
        },
        "id": "dzLKpmZICaWN"
      },
      "outputs": [],
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Import the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "This guide uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Fashion MNIST is intended as a drop-in replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) datasetâ€”often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc.) in a format identical to that of the articles of clothing you'll use here.\n",
        "\n",
        "This guide uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n",
        "\n",
        "Here, 60,000 images are used to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from PyTorch through *torchvision* library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T02:23:06.357055Z",
          "iopub.status.busy": "2022-02-05T02:23:06.356498Z",
          "iopub.status.idle": "2022-02-05T02:23:08.243268Z",
          "shell.execute_reply": "2022-02-05T02:23:08.243667Z"
        },
        "id": "7MqDQO0KCaWS"
      },
      "outputs": [],
      "source": [
        "# Loading the Fashion-MNIST dataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "# Download and load the training data\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.\n",
        "])\n",
        "\n",
        "# datasets\n",
        "trainset = datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transform)\n",
        "\n",
        "testset = datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=transform)\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqX__O5Hh5VJ"
      },
      "source": [
        "# A PyTorch implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkiQqJR4h5VL"
      },
      "source": [
        "## Import and wrap the Fashion MNIST dataset\n",
        "\n",
        "A good practice when using PyTorch is to extend the *Dataset* class to better manage data. Every subclasses must extend the following methods:\n",
        "\n",
        "*   **\\_\\_init\\_\\_** : class constructor, here are specified the data and the parameters;\n",
        "*   **\\_\\_getitem\\_\\_**: method called implicit later by the *dataloader* to pass the data to the model;\n",
        "*   **\\_\\_len\\_\\_**: method that specify the length of the dataset;\n",
        "\n",
        "Other methods can be added to better manage the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4Sg5LYviAlS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FashionDataset(Dataset):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T02:23:06.357055Z",
          "iopub.status.busy": "2022-02-05T02:23:06.356498Z",
          "iopub.status.idle": "2022-02-05T02:23:08.243268Z",
          "shell.execute_reply": "2022-02-05T02:23:08.243667Z"
        },
        "id": "zZf282W7h5VM"
      },
      "outputs": [],
      "source": [
        "dataset_train = FashionDataset(trainset)\n",
        "dataset_test = FashionDataset(testset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQKVf-Y-h5VT"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "Following the PyTorch best practice, a model is built by extending the `nn.Module` class. Even in this case every subclasses have to extend the following methods:\n",
        "\n",
        "*   **\\_\\_init\\_\\_**: class constructor, here are specified the layers of the model;\n",
        "*   **forward**: method that rapresent the forward pass of the model\n",
        "\n",
        "Methods for wrapping training, evaluation and prediction operation can be added in this class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa60H_tUlCTu"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "class FashionModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(FashionModel, self).__init__()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def train_classifier(self, dataloader, epochs, criterion, optimizer, device):\n",
        "        train_loss = []\n",
        "        train_accs = []\n",
        "\n",
        "        for ep in range(epochs):\n",
        "            self.train()\n",
        "            running_loss = 0.0\n",
        "            acc = 0\n",
        "            total = 0\n",
        "\n",
        "            for it, (images, labels) in enumerate(tqdm(dataloader)):\n",
        "\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                logits = self.forward(images)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                # Backpropagation\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Accuracy\n",
        "                predictions = torch.max(logits, 1).indices.to(device)\n",
        "\n",
        "                acc += (predictions.detach().cpu().numpy() == labels.detach().cpu().numpy()).sum()\n",
        "                total += len(labels)\n",
        "\n",
        "            epoch_loss = running_loss/len(train_loader)\n",
        "            train_loss.append(epoch_loss)\n",
        "\n",
        "            epoch_acc = acc*100/total\n",
        "            train_accs.append(epoch_acc)\n",
        "\n",
        "            print(f\"Epoch {ep+1}: Loss {round(epoch_loss, 3)} - Accuracy {round(epoch_acc, 2)}%\\n\")\n",
        "\n",
        "        return train_loss, train_accs\n",
        "\n",
        "\n",
        "    def eval_classifier(self, dataloader, device):\n",
        "        self.eval()\n",
        "        val_acc = 0\n",
        "\n",
        "        for it, (images, labels) in enumerate(tqdm(dataloader)):\n",
        "\n",
        "            with torch.no_grad():\n",
        "                images = images.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                logits = self.forward(images)\n",
        "\n",
        "                # Accuracy\n",
        "                predictions = torch.max(logits, 1).indices\n",
        "\n",
        "                val_acc += (predictions.detach().cpu().numpy() == labels.detach().cpu().numpy()).sum()\n",
        "\n",
        "        print(f\"\\nTrained model Accuracy on testset: {round(val_acc*100/len(dataloader), 3)}%\")\n",
        "\n",
        "\n",
        "    def predict(self, dataloader, device):\n",
        "        self.eval()\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        predictions = []\n",
        "        for it, (images, labels) in enumerate(tqdm(dataloader)):\n",
        "\n",
        "            with torch.no_grad():\n",
        "                images = images.to(device)\n",
        "\n",
        "                logits = self.forward(images)\n",
        "                preds = softmax(logits)\n",
        "\n",
        "                predictions.append(preds.detach().cpu().numpy()[0])\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T02:23:09.515540Z",
          "iopub.status.busy": "2022-02-05T02:23:09.514954Z",
          "iopub.status.idle": "2022-02-05T02:23:11.016295Z",
          "shell.execute_reply": "2022-02-05T02:23:11.015745Z"
        },
        "id": "abP5puLth5VU"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = FashionModel().to(device)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T02:23:11.032563Z",
          "iopub.status.busy": "2022-02-05T02:23:11.031996Z",
          "iopub.status.idle": "2022-02-05T02:23:45.127248Z",
          "shell.execute_reply": "2022-02-05T02:23:45.126760Z"
        },
        "id": "3J4-vSTDh5VW"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1)\n",
        "\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cabS3B-fq1fh"
      },
      "outputs": [],
      "source": [
        "train_loss, train_accs = model.train_classifier(train_loader, epochs, criterion, optimizer, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR2f7jrph5VX"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(epochs), train_loss)\n",
        "plt.xlabel(\"No. of Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpohl8Ljh5VX"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(epochs), train_accs)\n",
        "\n",
        "plt.xlabel(\"No. of Epoch\")\n",
        "plt.ylabel(\"Accuracy %\")\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvFn5OQbh5VY"
      },
      "source": [
        "### Evaluate accuracy\n",
        "\n",
        "Next, compare how the model performs on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T02:23:45.796585Z",
          "iopub.status.busy": "2022-02-05T02:23:45.796041Z",
          "iopub.status.idle": "2022-02-05T02:23:46.217066Z",
          "shell.execute_reply": "2022-02-05T02:23:46.217474Z"
        },
        "id": "8ZU35qSNh5Vd"
      },
      "outputs": [],
      "source": [
        "model.eval_classifier(test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmWxqEiuh5Vc"
      },
      "source": [
        "### Make predictions\n",
        "\n",
        "With the model trained, you can use it to make predictions about some images.\n",
        "Attach a softmax layer to convert the model's linear outputsâ€”[logits](https://developers.google.com/machine-learning/glossary#logits) to probabilities, which should be easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H4Q9tgoIofW"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYHi3oQ1h5Vh"
      },
      "source": [
        "Graph this to look at the full set of 10 class predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T02:23:46.244767Z",
          "iopub.status.busy": "2022-02-05T02:23:46.244181Z",
          "iopub.status.idle": "2022-02-05T02:23:46.246387Z",
          "shell.execute_reply": "2022-02-05T02:23:46.245908Z"
        },
        "id": "CBSZb7zqh5Vh"
      },
      "outputs": [],
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  true_label, img = true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  true_label = true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzF3BtSUh5Vh"
      },
      "source": [
        "### Verify predictions\n",
        "\n",
        "With the model trained, you can use it to make predictions about some images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUOFq6MGh5Vi"
      },
      "source": [
        "Let's look at the 0th image, predictions, and prediction array. Correct prediction labels are blue and incorrect prediction labels are red. The number gives the percentage (out of 100) for the predicted label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8oRugJbh5Vi"
      },
      "outputs": [],
      "source": [
        "test_images = dataset_test.get_images()\n",
        "test_labels = dataset_test.get_labels()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T02:23:46.285608Z",
          "iopub.status.busy": "2022-02-05T02:23:46.285071Z",
          "iopub.status.idle": "2022-02-05T02:23:46.364057Z",
          "shell.execute_reply": "2022-02-05T02:23:46.364410Z"
        },
        "id": "cPrgpl7Sh5Vi"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T02:23:46.395590Z",
          "iopub.status.busy": "2022-02-05T02:23:46.386856Z",
          "iopub.status.idle": "2022-02-05T02:23:46.477744Z",
          "shell.execute_reply": "2022-02-05T02:23:46.478119Z"
        },
        "id": "KdUPxDQVh5Vj"
      },
      "outputs": [],
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T02:23:46.495208Z",
          "iopub.status.busy": "2022-02-05T02:23:46.494656Z",
          "iopub.status.idle": "2022-02-05T02:23:48.120493Z",
          "shell.execute_reply": "2022-02-05T02:23:48.120884Z"
        },
        "id": "EmBvopABh5Vk"
      },
      "outputs": [],
      "source": [
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], test_labels)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "trexpl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}